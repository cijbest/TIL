library(KoNLP)
useSystemDic()
useSejongDic()
useNIADic()
library(KoNLP)
useSystemDic()
useSejongDic()
useNIADic()
install.packages("multilinguer")
install.packages(c("hash", "tau", "Sejong", "RSQLite", "devtools", "bit", "rex", "lazyeval", "htmlwidgets", "crosstalk", "promises", "later", "sessioninfo", "xopen", "bit64", "blob", "DBI", "memoise", "plogr", "covr", "DT", "rcmdcheck", "rversions"), type = "binary")
library(KoNLP)
useSystemDic()
useSejongDic()
useNIADic()
library(KoNLP)
useSystemDic()
useSejongDic()
useNIADic()
remotes::install_github('haven-jeon/KoNLP', upgrade = "never", INSTALL_opts=c("--no-multiarch"))
library(KoNLP)
useSystemDic()
useSejongDic()
useNIADic()
wd <- readLines("wc.txt",encoding="UTF-8")
wd2 <- sapply(wd, extractNoun, USE.NAMES = F)
install.packages("multilinguer")
install.packages(c("hash", "tau", "Sejong", "RSQLite", "devtools", "bit", "rex", "lazyeval", "htmlwidgets", "crosstalk", "promises", "later", "sessioninfo", "xopen", "bit64", "blob", "DBI", "memoise", "plogr", "covr", "DT", "rcmdcheck", "rversions"), type = "binary")
install.packages("remotes")
install.packages("remotes")
remotes::install_github('haven-jeon/KoNLP', upgrade = "never", INSTALL_opts=c("--no-multiarch"))
library(KoNLP)
useSystemDic()
library(KoNLP)
useSystemDic()
useSejongDic()
useNIADic()
wd <- readLines("wc.txt",encoding="UTF-8")
wd2 <- sapply(wd, extractNoun, USE.NAMES = F) # 단어 추출
wd2
lwd <- unlist(wd2)
lwd
lwd2 <- filter(function(x){
nchar(x) >= 2 # 단어길이가 2글자 이상인 것만
}, lwd)
lwd2
lwd2 <- Filter(function(x){
nchar(x) >= 2 # 단어길이가 2글자 이상인 것만
}, lwd)
lwd2
wc <- table(lwd)
wc
wc <- sort(wcm, decreasing = T)
wc <- sort(wc, decreasing = T)
wc
library(wordcloud2)
wordcloud2(wc, color = "random-light", backgroundColor = "black")
cd <- c("A","B","C","B","C","B","C","A")
cd
table(cd)
add_wd
lwd
lwd <- gsub("[0-9]","",lwd)
lwd <- gsub("[a-Z]","",lwd)
lwd <- gsub("[A-Z]","",lwd)
lwd <- gsub("\\W","",lwd)
lwd <- gsub("스트레스","",lwd)
wordcloud2(wc, color = "random-light", backgroundColor = "black")
lwd <- gsub("[0-9]","",lwd)
lwd <- gsub("[a-Z]","",lwd)
lwd <- gsub("[A-Z]","",lwd)
lwd <- gsub("\\W","",lwd)
lwd <- gsub("스트레스","",lwd)
lwd2 <- Filter(function(x){
nchar(x) >= 2 # 단어길이가 2글자 이상인 것만
}, lwd)
wc <- table(lwd)
wc <- sort(wc, decreasing = T)
wordcloud2(wc, color = "random-light", backgroundColor = "black")
lwd <- gsub("[0-9]","",lwd)
lwd <- gsub("[0-9]","",lwd)
lwd <- gsub("[a-Z]","",lwd)
lwd <- gsub("[A-Z]","",lwd)
lwd <- gsub("\\W","",lwd)
lwd <- gsub("스트레스","",lwd)
lwd2 <- Filter(function(x){
nchar(x) >= 2 # 단어길이가 2글자 이상인 것만
}, lwd)
wc <- table(lwd2)
wc <- sort(wc, decreasing = T)
wordcloud2(wc, color = "random-light", backgroundColor = "black")
savePlot(filename = "wc", type="png")
wc <- table(lwd2)
wc <- sort(wc, decreasing = T)
jpeg(filename = "p.jpg", width = 300, height = 300, quality = 120)
wordcloud2(wc, color = "random-light", backgroundColor = "black")
dev.off()
wc <- table(lwd2)
wc <- sort(wc, decreasing = T)
jpeg(filename = "p.jpg", width = 300, height = 300, quality = 120)
wordcloud2(wc, color = "random-light", backgroundColor = "black")
dev.off()
wd <- readLines("wc.txt",encoding="UTF-8")
wd2 <- sapply(wd, extractNoun, USE.NAMES = F) # 단어 추출
lwd <- unlist(wd2) # 단어를 리스트에 담음
# 단어 빼기
lwd <- gsub("[0-9]","",lwd)
lwd <- gsub("[a-Z]","",lwd)
lwd <- gsub("[A-Z]","",lwd)
lwd <- gsub("\\W","",lwd)
lwd <- gsub("","",lwd)
lwd <- gsub("스트레스","",lwd)
lwd2 <- Filter(function(x){
nchar(x) >= 2 # 단어길이가 2글자 이상인 것만
}, lwd)
wc <- table(lwd2)
wc <- sort(wc, decreasing = T)
jpeg(filename = "p.jpg", width = 300, height = 300, quality = 120)
wordcloud2(wc, color = "random-light", backgroundColor = "black")
dev.off() # R에서의 파이프라인 끊음
wordcloud2(wc, color = "random-light", backgroundColor = "black")
png(filename = "C:\R\day03\testPloat3.png", width = 300, height = 300, quality = 120)
print(plot(1:10, type = "1"))
dev.off() # R에서의 파이프라인 끊음
wd <- readLines("wc.txt",encoding="UTF-8")
wd
wd2 <- sapply(wd, extractNoun, USE.NAMES = F)
wd2
wd2 <- sapply(wd, extractNoun, USE.NAMES = T)
wd2
wd2 <- sapply(wd, extractNoun, USE.NAMES = F)
lwd <- unlist(wd2)
lwd
lwd <- gsub("[0-9]","",lwd)
lwd <- gsub("[a-Z]","",lwd)
lwd <- gsub("[A-Z]","",lwd)
lwd <- gsub("\\W","",lwd)
lwd <- gsub("","",lwd)
lwd <- gsub("스트레스","",lwd)
lwd <- gsub("[0-9]","",lwd)
lwd <- gsub("[a-z]","",lwd)
lwd <- gsub("[A-Z]","",lwd)
lwd <- gsub("\\W","",lwd)
lwd <- gsub("","",lwd)
lwd <- gsub("스트레스","",lwd)
lwd
lwd2 <- Filter(function(x){
nchar(x) >= 2 # 단어길이가 2글자 이상인 것만
}, lwd)
lwd2
wc <- table(lwd2)
wc
wc <- sort(wc, decreasing = T)
wc
library(wordcloud)
library(tm)
library(RCurl)
library(RColorBrewer)
install.packages("wordcloud")
install.packages("tm")
install.packages("RCurl")
install.packages("RColorBrewer")
install.packages("RColorBrewer")
library(wordcloud)
library(tm)
library(RCurl)
library(RColorBrewer)
jpeg(filename = "1p.jpg", width = 300, height = 300, quality = 120)
palate <- brewer.pal(9,"Set1")
wordcloud(names(wc),
freq=wc,
scale=c(5,0,5),
rot.per=0.35,
min.freq=1,
random.order=F,
random.color=T,
colors=palate)
dev.off() # R에서의 파이프라인 끊음
wd <- readLines("https://www.seoul.co.kr/",encoding="UTF-8")
wd
wd <- readLines("https://www.seoul.co.kr/",encoding="EUC-KR")
wd
wd <- readLines("https://www.seoul.co.kr/news/newsView.php?id=20201008500059",encoding="EUC-KR")
wd
wd <- readLines("https://www.nongmin.com/news/NEWS/POL/ETC/327549/view",encoding="EUC-KR")
wd
library(KoNLP)
library(wordcloud)
library(tm)
library(RCurl)
library(RColorBrewer)
# Dictionary Setting
useSystemDic()
useSejongDic()
useNIADic()
# Dictionary에 내가 원하는 명사 추가
add_wd <- c("코비드", "코비드19", "코로나")
buildDictionary(user_dic=data.frame(
add_wd, rep("ncn",length(add_wd))
), replace_usr_dic=T)
# 텍스트 가져오기
wd <- readLines("https:/www.nongmin.com/news/NEWS/POL/ETC/327549/view",encoding="EUC-KR")
# 단어 추출
wd2 <- sapply(wd, extractNoun, USE.NAMES = F)
# 단어를 리스트에 담음
lwd <- unlist(wd2)
# 특정 문자 빼기
lwd <- gsub("[0-9]","",lwd)
lwd <- gsub("[a-z]","",lwd)
lwd <- gsub("[A-Z]","",lwd)
lwd <- gsub("\\W","",lwd) #특수문자
lwd <- gsub("","",lwd) # 공백
# 단어길이가 2글자 이상인 것만 추출
lwd2 <- Filter(function(x){
nchar(x) >= 2
}, lwd)
wc <- table(lwd2)
wc
wd <- readLines("https:/www.nongmin.com/news/NEWS/POL/ETC/327549/view",encoding="UTF-8")
# 단어 추출
wd2 <- sapply(wd, extractNoun, USE.NAMES = F)
# 단어를 리스트에 담음
lwd <- unlist(wd2)
# 특정 문자 빼기
lwd <- gsub("[0-9]","",lwd)
lwd <- gsub("[a-z]","",lwd)
lwd <- gsub("[A-Z]","",lwd)
lwd <- gsub("\\W","",lwd) #특수문자
lwd <- gsub("","",lwd) # 공백
lwd <- gsub("","",lwd)
# 단어길이가 2글자 이상인 것만 추출
lwd2 <- Filter(function(x){
nchar(x) >= 2
}, lwd)
wc <- table(lwd2)
wc
# 텍스트 가져오기
wd <- readLines("https:/www.nongmin.com/news/NEWS/POL/ETC/327549/view",encoding="UTF-8")
# Dictionary에 내가 원하는 명사 추가
add_wd <- c("코비드", "코비드19", "코로나")
buildDictionary(user_dic=data.frame(
add_wd, rep("ncn",length(add_wd))
), replace_usr_dic=T)
# 텍스트 가져오기
wd <- readLines("https:/www.nongmin.com/news/NEWS/POL/ETC/327549/view",encoding="UTF-8")
# 단어 추출
wd2 <- sapply(wd, extractNoun, USE.NAMES = F)
# 단어를 리스트에 담음
lwd <- unlist(wd2)
# 특정 문자 빼기
lwd <- gsub("[0-9]","",lwd)
lwd <- gsub("[a-z]","",lwd)
lwd <- gsub("[A-Z]","",lwd)
lwd <- gsub("\\W","",lwd) #특수문자
lwd <- gsub("","",lwd) # 공백
lwd <- gsub("","",lwd)
# 단어길이가 2글자 이상인 것만 추출
lwd2 <- Filter(function(x){
nchar(x) >= 2
}, lwd)
# 테이블에 담음
wc <- table(lwd2)
# 많이 나온 단어순으로 정렬
# head() : sort된 것 중에 100개만
wc <- head(sort(wc, decreasing = T), 100)
# palate에 표시
jpeg(filename = "1p.jpg", width = 300, height = 300, quality = 120)
palate <- brewer.pal(9,"Set1")  # 몇 가지 색상, 어떤 palate 쓸건지 지정
wordcloud(names(wc),
freq=wc,
scale=c(5,0,5),
rot.per=0.35,
min.freq=1,
random.order=F,
random.color=T,
colors=palate)
dev.off() # R에서의 파이프라인 끊음
lwd <- gsub("[0-9]","",lwd)
lwd <- gsub("[a-z]","",lwd)
lwd <- gsub("[A-Z]","",lwd)
lwd <- gsub("\\W","",lwd) #특수문자
lwd <- gsub("","",lwd) # 공백
lwd <- gsub("_","",lwd)
lwd <- gsub("__","",lwd)
lwd <- gsub("___","",lwd)
# 단어길이가 2글자 이상인 것만 추출
lwd2 <- Filter(function(x){
nchar(x) >= 2
}, lwd)
# 테이블에 담음
wc <- table(lwd2)
# 많이 나온 단어순으로 정렬
# head() : sort된 것 중에 100개만
wc <- head(sort(wc, decreasing = T), 100)
# palate에 표시
jpeg(filename = "1p.jpg", width = 300, height = 300, quality = 120)
palate <- brewer.pal(9,"Set1")  # 몇 가지 색상, 어떤 palate 쓸건지 지정
wordcloud(names(wc),
freq=wc,
scale=c(5,0,5),
rot.per=0.35,
min.freq=1,
random.order=F,
random.color=T,
colors=palate)
dev.off() # R에서의 파이프라인 끊음
# palate에 표시
jpeg(filename = "2p.jpg", width = 300, height = 300, quality = 120)
palate <- brewer.pal(9,"Set1")  # 몇 가지 색상, 어떤 palate 쓸건지 지정
wordcloud(names(wc),
freq=wc,
scale=c(5,0,5),
rot.per=0.35,
min.freq=1,
random.order=F,
random.color=T,
colors=palate)
dev.off() # R에서의 파이프라인 끊음
palate
wordcloud(names(wc),
freq=wc,
scale=c(5,0,5),
rot.per=0.35,
min.freq=1,
random.order=F,
random.color=T,
colors=palate)
wd <- readLines("https:/www.nongmin.com/news/NEWS/POL/ETC/327549/view",encoding="UTF-8")
# 텍스트 가져오기
wd <- readLines("https://www.nongmin.com/news/NEWS/POL/ETC/327549/view",encoding="UTF-8")
# 단어 추출
wd2 <- sapply(wd, extractNoun, USE.NAMES = F)
# 단어를 리스트에 담음
lwd <- unlist(wd2)
# 특정 문자 빼기
lwd <- gsub("[0-9]","",lwd)
lwd <- gsub("[a-z]","",lwd)
lwd <- gsub("[A-Z]","",lwd)
lwd <- gsub("\\W","",lwd) #특수문자
lwd <- gsub("","",lwd) # 공백
lwd <- gsub("_","",lwd)
lwd <- gsub("__","",lwd)
lwd <- gsub("___","",lwd)
# 단어길이가 2글자 이상인 것만 추출
lwd2 <- Filter(function(x){
nchar(x) >= 2
}, lwd)
# 테이블에 담음
wc <- table(lwd2)
# 많이 나온 단어순으로 정렬
# head() : sort된 것 중에 100개만
wc <- head(sort(wc, decreasing = T), 100)
# palate에 표시
jpeg(filename = "2p.jpg", width = 300, height = 300, quality = 120)
palate <- brewer.pal(9,"Set1")  # 몇 가지 색상, 어떤 palate 쓸건지 지정
wordcloud(names(wc),
freq=wc,
scale=c(5,0,5),
rot.per=0.35,
min.freq=1,
random.order=F,
random.color=T,
colors=palate)
dev.off() # R에서의 파이프라인 끊음
wordcloud(names(wc),
freq=wc,
scale=c(5,0,5),
rot.per=0.35,
min.freq=1,
random.order=F,
random.color=T,
colors=palate)
add_wd <- c("코비드", "코비드19", "코로나")
buildDictionary(user_dic=data.frame(
add_wd, rep("ncn",length(add_wd))
), replace_usr_dic=T)
wd <- readLines("wc.txt",encoding="UTF-8")
wd2 <- sapply(wd, extractNoun, USE.NAMES = F) # 단어 추출
lwd <- unlist(wd2) # 단어를 리스트에 담음
# 단어 빼기
lwd <- gsub("[0-9]","",lwd)
lwd <- gsub("[a-z]","",lwd)
lwd <- gsub("[A-Z]","",lwd)
lwd <- gsub("\\W","",lwd)
lwd <- gsub("","",lwd)
lwd <- gsub("스트레스","",lwd)
lwd2 <- Filter(function(x){
nchar(x) >= 2 # 단어길이가 2글자 이상인 것만
}, lwd)
wc <- table(lwd2)
wc <- sort(wc, decreasing = T) # 많이 나온 단어순으로 정렬
jpeg(filename = "1p.jpg", width = 300, height = 300, quality = 120)
palate <- brewer.pal(9,"Set1")  # 몇 가지 색상, 어떤 palate 쓸건지 지정
wordcloud(names(wc),
freq=wc,
scale=c(5,0,5),
rot.per=0.35,
min.freq=1,
random.order=F,
random.color=T,
colors=palate)
dev.off() # R에서의 파이프라인 끊음
middle_mid_exam <- read.csv("middle_mid_exam.xlsx",
header = T,
stringsAsFactors=F,
fileEncoding="UTF-8"
)
library(dplyr)
# 1
middle_mid_exam <- read.csv("middle_mid_exam.xlsx",
header = T,
stringsAsFactors=F,
fileEncoding="UTF-8"
)
middle_mid_exam <- read.csv("middle_mid_exam.xlsx",
header = T,
stringsAsFactors=F,
fileEncoding="UTF-8"
)
middle_mid_exam <- read.csv("middle_mid_exam.xlsx",
header = F,
stringsAsFactors=F,
fileEncoding="UTF-8"
)
middle_mid_exam <- read.excel("middle_mid_exam.xlsx")
middle_mid_exam <- read_excel("middle_mid_exam.xlsx")
middle_mid_exam <- as.data.frame(read_excel("middle_mid_exam.xlsx"))
library(readxl)
middle_mid_exam <- read_excel("middle_mid_exam.xlsx")
library(readxl)
install.packages("readxl")
library(readxl)
install.packages("readxl")
install.packages("readxl")
install.packages("readxl")
library(readxl)
library(readxl)
middle_mid_exam <- read_excel("middle_mid_exam.xlsx")
middle_mid_exam
MATHEMATICS <- dcast(middle_mid_exam, CLASS)
library(reshape2)
MATHEMATICS <- dcast(middle_mid_exam, CLASS)
MATHEMATICS <- dcast(middle_mid_exam, ID ~ CLASS)
MATHEMATICS
MATHEMATICS <- dcast(middle_mid_exam, ID ~ CLASS, mean)
MATHEMATICS
MATHEMATICS <- dcast(middle_mid_exam, ID ~ CLASS ~ MATHEMATICS, mean)
MATHEMATICS <- dcast(middle_mid_exam, ID ~ CLASS value.var=MATHEMATICS)
MATHEMATICS <- dcast(middle_mid_exam, c(ID, CLASS) ~ MATHEMATICS)
MATHEMATICS <- melt(middle_mid_exam,c(ID, CLASS), na.rm = TRUE)
library(readxl)
MATHEMATICS <- melt(middle_mid_exam,id.vars = c(ID, CLASS), na.rm = TRUE)
# 2
MATHEMATICS <- melt(middle_mid_exam,id.vars = ID, na.rm = TRUE)
middle_mid_exam
library(readxl)
library(reshape2)
# 1
middle_mid_exam <- read_excel("middle_mid_exam.xlsx")
MATHEMATICS <- melt(middle_mid_exam,id.vars = ID, na.rm = TRUE)
MATHEMATICS <- dcast(middle_mid_exam, c("ID", "CLASS") ~ MATHEMATICS)
MATHEMATICS
MATHEMATICS <- dcast(middle_mid_exam, ID ~ CLASS ~ MATHEMATICS)
MATHEMATICS
MATHEMATICS <- dcast(middle_mid_exam, ID, CLASS ~ MATHEMATICS)
# 2
MATHEMATICS <- dcast(middle_mid_exam, ID~ MATHEMATICS)
MATHEMATICS
middle_mid_exam
names(middle_mid_exam) <- tolower(names(middle_mid_exam))
m_MATHEMATICS <- melt(middle_mid_exam, id=c("id","class"))
m_MATHEMATICS
middle_mid_exam <- read_excel("middle_mid_exam.xlsx")
middle_mid_exam
MATHEMATICS <- dcast(middle_mid_exam, ID + CLASS ~ MATHEMATICS)
MATHEMATICS
library(dplyr)
MATHEMATICS <- middle_mid_exam %>% select(ID, CLASS, MATHEMATICS)
MATHEMATICS
MATHEMATICS
MATHEMATICS <- dcast(middle_mid_exam, ID ~ CLASS)
MATHEMATICS
middle_mid_exam %>% select(ID, CLASS, ENGLISH)
ENGLISH <- middle_mid_exam %>% select(ID, CLASS, ENGLISH)
dcast(middle_mid_exam, ID ~ CLASS)
ENGLISH <- dcast(middle_mid_exam, ID ~ CLASS)
library(readxl)
library(reshape2)
library(dplyr)
# 1
middle_mid_exam <- read_excel("middle_mid_exam.xlsx")
# 2
MATHEMATICS <- middle_mid_exam %>% select(ID, CLASS, MATHEMATICS)
MATHEMATICS <- dcast(MATHEMATICS, ID ~ CLASS)
ENGLISH <- middle_mid_exam %>% select(ID, CLASS, ENGLISH)
ENGLISH <- dcast(ENGLISH, ID ~ CLASS)
MATHEMATICS
ENGLISH
middle_mid_exam %>% group_by(CLASS) %>% summarise(ENG_MEAN=mean(ENGLISH))
middle_mid_exam %>% group_by(CLASS) %>% summarise(MATH_MEAN=mean(MATHEMATICS))
middle_mid_exam %>% group_by(CLASS) %>% summarise(ENG_MEAN=mean(ENGLISH), ENG_SUM=sum(ENGLISH))
middle_mid_exam %>% group_by(CLASS) %>% summarise(MATH_MEAN=mean(MATHEMATICS), MATH_SUM=sum(MATHEMATICS))
# 4
MATHEMATICS %>% Filter(class1 >= 80)
MATHEMATICS %>% summarise(Filter(class1 >= 80))
MATHEMATICS
summarise(Filter(MATHEMATICS, class1 >= 80))
Filter(MATHEMATICS, class1 >= 80) %>% summarise(n())
filter(MATHEMATICS, class1 >= 80) %>% summarise(n())
middle_mid_exam %>% arrange(desc(MATHEMATICS), ENGLISH)
middle_mid_exam %>% filter(MATHEMATICS >= 80, ENGLISH >= 85) %>% summarise(n())
MATHEMATICS %>% filter(class1 >= 80) %>% summarise(n())
middle_mid_exam %>% filter(MATHEMATICS >= 80 & ENGLISH >= 85) %>% summarise(n())
